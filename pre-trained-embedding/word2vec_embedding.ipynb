{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "sequence_embedding.ipynb",
   "provenance": [],
   "toc_visible": true,
   "machine_shape": "hm"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0c5d052a9c9946018f552e1126911922": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_e101cc846d7c4b858b0cd0627322b07a",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_c2413d5f19624437a6474fe9b10ebcab",
       "IPY_MODEL_fe17d6cb96284a4e97b441dff67f35c9"
      ]
     }
    },
    "e101cc846d7c4b858b0cd0627322b07a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "c2413d5f19624437a6474fe9b10ebcab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_b2b4efe8dc734fbe9d737e6b5d30ba34",
      "_dom_classes": [],
      "description": "100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 711838,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 711838,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_53fd6c178331432c8501b03ad37f2d2c"
     }
    },
    "fe17d6cb96284a4e97b441dff67f35c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_718195d169fb4281a0f97db65b5d14ac",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 711838/711838 [5:12:03&lt;00:00, 38.02it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_e5f88726f92d4ef7910e3049e62adc4c"
     }
    },
    "b2b4efe8dc734fbe9d737e6b5d30ba34": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "53fd6c178331432c8501b03ad37f2d2c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "718195d169fb4281a0f97db65b5d14ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "e5f88726f92d4ef7910e3049e62adc4c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzNjAsjnqq9G"
   },
   "source": [
    "This vector embedding is generated using a skip-gram Word2Vec algorithm.\n",
    "For more information see:\n",
    "[tensorflow](https://www.tensorflow.org/tutorials/text/word2vec)\n",
    "[word2vec](http://jalammar.github.io/illustrated-word2vec/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "iFDXX_BctsNl",
    "outputId": "a9dc85b7-852e-4788-debd-bcbfb26ac015",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# Install your required packages here\n",
    "!pip install pandas numpy matplotlib sklearn fsspec gcsfs"
   ],
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.6/dist-packages (0.8.4)\n",
      "Requirement already satisfied: gcsfs in /usr/local/lib/python3.6/dist-packages (0.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.23.0)\n",
      "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.17.2)\n",
      "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.6/dist-packages (from gcsfs) (3.7.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (50.3.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (1.6.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (5.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (20.2.0)\n",
      "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->gcsfs) (3.7.4.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth>=1.2->gcsfs) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Frh7Q8NUtQSX",
    "outputId": "e91f99fa-093a-4129-fd43-513d1c583ba6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "!pip install keras\n",
    "!pip install -q tqdm"
   ],
   "execution_count": 50,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KOPn9sTRTCG_",
    "outputId": "69571c67-2e6c-4276-93af-0da136a51ced",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ],
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% Colab\n"
    },
    "id": "0dWrynsztsNx",
    "outputId": "b40a7a2e-6590-42d8-83f6-954f3991c1a4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# Path to credentials for cloud bucket:\n",
    "%env GOOGLE_APPLICATION_CREDENTIALS=/content/drive/My Drive/CS/AI/Credentials/ai-project-2020-f4dfbc25326c.json"
   ],
   "execution_count": 52,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "env: GOOGLE_APPLICATION_CREDENTIALS=/content/drive/My Drive/CS/AI/Credentials/ai-project-2020-f4dfbc25326c.json\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% Imports\n"
    },
    "id": "fbqTt3ZgtsOE"
   },
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "import pandas as pd\n",
    "import tqdm.notebook as tqdm\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dot, Embedding, Flatten, GlobalAveragePooling1D, Reshape\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, Dropout\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins import projector\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% Colab\n"
    },
    "id": "AUizP0x4tsOJ",
    "outputId": "2b68bdef-3a96-4dd9-ac62-b21718b07185",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": 55,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "x99ytp8JtsOU"
   },
   "source": [
    "# define constants\n",
    "bucket_name = \"ai-project-2020-spotify\"\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket(bucket_name)"
   ],
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "f0yUPzSYtsOd",
    "outputId": "0d801e27-9d3d-42ba-fdfe-fee9c3755629",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "train_files = list(bucket.list_blobs(prefix='training_set/'))\n",
    "for blob in [blob for blob in train_files if '20180715' in blob.name]:\n",
    "  print(blob.name)"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "training_set/log_0_20180715_000000000000.csv.gz\n",
      "training_set/log_1_20180715_000000000000.csv.gz\n",
      "training_set/log_2_20180715_000000000000.csv.gz\n",
      "training_set/log_3_20180715_000000000000.csv.gz\n",
      "training_set/log_4_20180715_000000000000.csv.gz\n",
      "training_set/log_5_20180715_000000000000.csv.gz\n",
      "training_set/log_6_20180715_000000000000.csv.gz\n",
      "training_set/log_7_20180715_000000000000.csv.gz\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "67-OT_4ttsOk",
    "outputId": "e7290f37-9783-4af8-8767-b07936bbd8ea",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "logs_0 = pd.read_csv(f\"gs://{bucket_name}/training_set/log_0_20180715_000000000000.csv.gz\")\n",
    "logs_1 = pd.read_csv(f\"gs://{bucket_name}/training_set/log_1_20180715_000000000000.csv.gz\")\n",
    "logs_2 = pd.read_csv(f\"gs://{bucket_name}/training_set/log_2_20180715_000000000000.csv.gz\")\n",
    "logs_3 = pd.read_csv(f\"gs://{bucket_name}/training_set/log_3_20180715_000000000000.csv.gz\")\n",
    "logs = logs_0.append(logs_1).append(logs_2).append(logs_3)\n",
    "logs.shape"
   ],
   "execution_count": 58,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(11927861, 21)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 58
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% Unique Track IDs\n"
    },
    "id": "MBqkIMD0tsOp",
    "outputId": "4783e232-bb4f-4ec7-86f4-3127e18c61fb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "unique_tracks = logs['track_id_clean'].nunique()\n",
    "print(unique_tracks)"
   ],
   "execution_count": 59,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "661694\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% Data Preprocessing\n"
    },
    "id": "tAsCh4JTtsOu",
    "outputId": "a928a937-6009-4c7e-a051-34819ad1da92",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    }
   },
   "source": [
    "logs_dropped = logs[['session_id','session_position','track_id_clean']]\n",
    "logs_dropped.head()"
   ],
   "execution_count": 60,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_position</th>\n",
       "      <th>track_id_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_00006f66-33e5-4de7-a324-2d18e439fc1e</td>\n",
       "      <td>1</td>\n",
       "      <td>t_0479f24c-27d2-46d6-a00c-7ec928f2b539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_00006f66-33e5-4de7-a324-2d18e439fc1e</td>\n",
       "      <td>2</td>\n",
       "      <td>t_9099cd7b-c238-47b7-9381-f23f2c1d1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_00006f66-33e5-4de7-a324-2d18e439fc1e</td>\n",
       "      <td>3</td>\n",
       "      <td>t_fc5df5ba-5396-49a7-8b29-35d0d28249e0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_00006f66-33e5-4de7-a324-2d18e439fc1e</td>\n",
       "      <td>4</td>\n",
       "      <td>t_23cff8d6-d874-4b20-83dc-94e450e8aa20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_00006f66-33e5-4de7-a324-2d18e439fc1e</td>\n",
       "      <td>5</td>\n",
       "      <td>t_64f3743c-f624-46bb-a579-0f3f9a07a123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               session_id  ...                          track_id_clean\n",
       "0  0_00006f66-33e5-4de7-a324-2d18e439fc1e  ...  t_0479f24c-27d2-46d6-a00c-7ec928f2b539\n",
       "1  0_00006f66-33e5-4de7-a324-2d18e439fc1e  ...  t_9099cd7b-c238-47b7-9381-f23f2c1d1043\n",
       "2  0_00006f66-33e5-4de7-a324-2d18e439fc1e  ...  t_fc5df5ba-5396-49a7-8b29-35d0d28249e0\n",
       "3  0_00006f66-33e5-4de7-a324-2d18e439fc1e  ...  t_23cff8d6-d874-4b20-83dc-94e450e8aa20\n",
       "4  0_00006f66-33e5-4de7-a324-2d18e439fc1e  ...  t_64f3743c-f624-46bb-a579-0f3f9a07a123\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 60
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% Label Encoder\n"
    },
    "id": "vhjzJewBtsO1",
    "outputId": "6e79d89e-be32-4d23-8ba9-20722ccf47de",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "encoder = LabelEncoder()\n",
    "logs_dropped['track_id_clean'] = encoder.fit_transform(logs_dropped['track_id_clean'])\n",
    "logs_dropped.info()"
   ],
   "execution_count": 61,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11927861 entries, 0 to 2972977\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Dtype \n",
      "---  ------            ----- \n",
      " 0   session_id        object\n",
      " 1   session_position  int64 \n",
      " 2   track_id_clean    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 364.0+ MB\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "FLViia-9tsO7"
   },
   "source": [
    "def stack_sessions(df):\n",
    "    \"\"\"\n",
    "    Turn matrix representation into vector by stacking the listen events together (as columns)\n",
    "    For example:\n",
    "    session_id session_position feature1 feature2\n",
    "    a          1                ~        ~\n",
    "    a          2                ~        ~\n",
    "    b          1                ~        ~\n",
    "    b          2                ~        ~\n",
    "    b          3                ~        ~\n",
    "\n",
    "    Turns into:\n",
    "    session_id 1_feature1 1_feature2 2_feature1 2_feature2 3_feature1 3_feature2\n",
    "    a          ~          ~          ~          ~          Nan        Nan\n",
    "    b          ~          ~          ~          ~          ~          ~\n",
    "    \"\"\"\n",
    "    columns = list(df.columns)\n",
    "    columns.remove('session_id')\n",
    "    columns.remove('session_position')\n",
    "    sessions = df.pivot(index='session_id', columns='session_position', values=columns)\n",
    "    return sessions"
   ],
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% Data Processing\n"
    },
    "id": "eC1lcwrptsO_",
    "outputId": "9c29aaf6-34dc-4e4d-80f6-33b8a7a595b0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    }
   },
   "source": [
    "# Stack all Sessions\n",
    "stacked_sessions = stack_sessions(logs_dropped)\n",
    "# Drop all features except track_id, skip_2, session_ids\n",
    "stacked_sessions.head()"
   ],
   "execution_count": 63,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"20\" halign=\"left\">track_id_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_position</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_0000469e-70c4-4b69-8ac3-94417a4fe83b</th>\n",
       "      <td>659475.0</td>\n",
       "      <td>210319.0</td>\n",
       "      <td>659475.0</td>\n",
       "      <td>371696.0</td>\n",
       "      <td>371696.0</td>\n",
       "      <td>659475.0</td>\n",
       "      <td>210319.0</td>\n",
       "      <td>103502.0</td>\n",
       "      <td>42262.0</td>\n",
       "      <td>22240.0</td>\n",
       "      <td>584465.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_00005fe5-8086-4ea4-a02f-bbe820af6067</th>\n",
       "      <td>365581.0</td>\n",
       "      <td>61084.0</td>\n",
       "      <td>123857.0</td>\n",
       "      <td>430647.0</td>\n",
       "      <td>371696.0</td>\n",
       "      <td>469729.0</td>\n",
       "      <td>37003.0</td>\n",
       "      <td>483074.0</td>\n",
       "      <td>399162.0</td>\n",
       "      <td>483074.0</td>\n",
       "      <td>37003.0</td>\n",
       "      <td>469729.0</td>\n",
       "      <td>371696.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_000069dc-3d86-4e96-a221-d10eb55d0573</th>\n",
       "      <td>386645.0</td>\n",
       "      <td>363460.0</td>\n",
       "      <td>541696.0</td>\n",
       "      <td>542294.0</td>\n",
       "      <td>541696.0</td>\n",
       "      <td>542294.0</td>\n",
       "      <td>351913.0</td>\n",
       "      <td>5332.0</td>\n",
       "      <td>149087.0</td>\n",
       "      <td>651417.0</td>\n",
       "      <td>78862.0</td>\n",
       "      <td>163045.0</td>\n",
       "      <td>256064.0</td>\n",
       "      <td>457436.0</td>\n",
       "      <td>17511.0</td>\n",
       "      <td>111579.0</td>\n",
       "      <td>199421.0</td>\n",
       "      <td>487463.0</td>\n",
       "      <td>562817.0</td>\n",
       "      <td>315182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_00006f66-33e5-4de7-a324-2d18e439fc1e</th>\n",
       "      <td>11556.0</td>\n",
       "      <td>374221.0</td>\n",
       "      <td>652113.0</td>\n",
       "      <td>92782.0</td>\n",
       "      <td>261423.0</td>\n",
       "      <td>517298.0</td>\n",
       "      <td>584811.0</td>\n",
       "      <td>30884.0</td>\n",
       "      <td>630103.0</td>\n",
       "      <td>111205.0</td>\n",
       "      <td>314190.0</td>\n",
       "      <td>271906.0</td>\n",
       "      <td>232822.0</td>\n",
       "      <td>417499.0</td>\n",
       "      <td>351706.0</td>\n",
       "      <td>567592.0</td>\n",
       "      <td>496409.0</td>\n",
       "      <td>494671.0</td>\n",
       "      <td>42335.0</td>\n",
       "      <td>138798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_000073ea-37e3-473d-8197-bd64d7b16d31</th>\n",
       "      <td>335883.0</td>\n",
       "      <td>416530.0</td>\n",
       "      <td>225569.0</td>\n",
       "      <td>327178.0</td>\n",
       "      <td>127293.0</td>\n",
       "      <td>309946.0</td>\n",
       "      <td>77144.0</td>\n",
       "      <td>483074.0</td>\n",
       "      <td>215003.0</td>\n",
       "      <td>129887.0</td>\n",
       "      <td>312662.0</td>\n",
       "      <td>107808.0</td>\n",
       "      <td>498700.0</td>\n",
       "      <td>433865.0</td>\n",
       "      <td>539743.0</td>\n",
       "      <td>629665.0</td>\n",
       "      <td>363037.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       track_id_clean  ...          \n",
       "session_position                                   1   ...        20\n",
       "session_id                                             ...          \n",
       "0_0000469e-70c4-4b69-8ac3-94417a4fe83b       659475.0  ...       NaN\n",
       "0_00005fe5-8086-4ea4-a02f-bbe820af6067       365581.0  ...       NaN\n",
       "0_000069dc-3d86-4e96-a221-d10eb55d0573       386645.0  ...  315182.0\n",
       "0_00006f66-33e5-4de7-a324-2d18e439fc1e        11556.0  ...  138798.0\n",
       "0_000073ea-37e3-473d-8197-bd64d7b16d31       335883.0  ...       NaN\n",
       "\n",
       "[5 rows x 20 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 63
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dGpAE-7xOY3o",
    "outputId": "bbac6a47-f85b-4e43-b43f-59ba9628e0aa",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    }
   },
   "source": [
    "# Drop second part of session\n",
    "# Go back from float to int\n",
    "stacked_sessions.reset_index(inplace=True)\n",
    "stacked_sessions.drop(columns=['session_id'], inplace=True)\n",
    "for index in range(11,21):\n",
    "  stacked_sessions.drop(columns=[('track_id_clean', index)], inplace=True)\n",
    "for index in range(1,11):\n",
    "  stacked_sessions[('track_id_clean', index)] = stacked_sessions[('track_id_clean', index)].astype(int)\n",
    "stacked_sessions.head()"
   ],
   "execution_count": 64,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:3887: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">track_id_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_position</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>659475</td>\n",
       "      <td>210319</td>\n",
       "      <td>659475</td>\n",
       "      <td>371696</td>\n",
       "      <td>371696</td>\n",
       "      <td>659475</td>\n",
       "      <td>210319</td>\n",
       "      <td>103502</td>\n",
       "      <td>42262</td>\n",
       "      <td>22240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365581</td>\n",
       "      <td>61084</td>\n",
       "      <td>123857</td>\n",
       "      <td>430647</td>\n",
       "      <td>371696</td>\n",
       "      <td>469729</td>\n",
       "      <td>37003</td>\n",
       "      <td>483074</td>\n",
       "      <td>399162</td>\n",
       "      <td>483074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>386645</td>\n",
       "      <td>363460</td>\n",
       "      <td>541696</td>\n",
       "      <td>542294</td>\n",
       "      <td>541696</td>\n",
       "      <td>542294</td>\n",
       "      <td>351913</td>\n",
       "      <td>5332</td>\n",
       "      <td>149087</td>\n",
       "      <td>651417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11556</td>\n",
       "      <td>374221</td>\n",
       "      <td>652113</td>\n",
       "      <td>92782</td>\n",
       "      <td>261423</td>\n",
       "      <td>517298</td>\n",
       "      <td>584811</td>\n",
       "      <td>30884</td>\n",
       "      <td>630103</td>\n",
       "      <td>111205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>335883</td>\n",
       "      <td>416530</td>\n",
       "      <td>225569</td>\n",
       "      <td>327178</td>\n",
       "      <td>127293</td>\n",
       "      <td>309946</td>\n",
       "      <td>77144</td>\n",
       "      <td>483074</td>\n",
       "      <td>215003</td>\n",
       "      <td>129887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id_clean                  ...                        \n",
       "session_position             1       2       3   ...      8       9       10\n",
       "0                        659475  210319  659475  ...  103502   42262   22240\n",
       "1                        365581   61084  123857  ...  483074  399162  483074\n",
       "2                        386645  363460  541696  ...    5332  149087  651417\n",
       "3                         11556  374221  652113  ...   30884  630103  111205\n",
       "4                        335883  416530  225569  ...  483074  215003  129887\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 64
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TtQs1Ja2-Z6_",
    "outputId": "2899383e-a008-4087-879f-1aacd3a4360f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "sequences = stacked_sessions.values.tolist()\n",
    "len_sequences = len(sequences)\n",
    "print(len_sequences)"
   ],
   "execution_count": 65,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "711838\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f42HOruWBzIx"
   },
   "source": [
    "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
    "# (int-encoded sentences) based on window size, number of negative samples\n",
    "# and vocabulary size.\n",
    "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
    "  # Build the sampling table for vocab_size tokens.\n",
    "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "  # Open a tfrecord writer\n",
    "  current_date_and_time = datetime.datetime.now().date()\n",
    "  current_date_and_time_string = str(current_date_and_time)\n",
    "  writer = tf.io.TFRecordWriter('/content/drive/MyDrive/CS/AI/Data/embedding_training_data_'+current_date_and_time_string+'.tfrecord')\n",
    "  positive_skipgrams_total = 0\n",
    "  negative_skipgrams_total = 0\n",
    "\n",
    "  # Iterate over all sequences (sentences) in dataset.\n",
    "  for sequence in tqdm.tqdm(sequences):\n",
    "\n",
    "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
    "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "          sequence, \n",
    "          vocabulary_size=vocab_size,\n",
    "          sampling_table=sampling_table,\n",
    "          window_size=window_size,\n",
    "          negative_samples=0)\n",
    "    positive_skipgrams_total += len(positive_skip_grams)\n",
    "\n",
    "    # Iterate over each positive skip-gram pair to produce training examples \n",
    "    # with positive context word and negative samples.\n",
    "    for target_word, context_word in positive_skip_grams:\n",
    "      context_class = tf.expand_dims(\n",
    "          tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "          true_classes=context_class,\n",
    "          num_true=1, \n",
    "          num_sampled=num_ns, \n",
    "          unique=True, \n",
    "          range_max=vocab_size, \n",
    "          seed=SEED, \n",
    "          name=\"negative_sampling\")\n",
    "\n",
    "      # Build context and label vectors (for one target word)\n",
    "      negative_sampling_candidates = tf.expand_dims(\n",
    "          negative_sampling_candidates, 1)\n",
    "      \n",
    "      proto_tensor = tf.make_tensor_proto(negative_sampling_candidates) \n",
    "      negative_sampling_candidates = tf.make_ndarray(proto_tensor).tolist()\n",
    "      negative_sampling_candidates_flat = [item for sublist in negative_sampling_candidates for item in sublist]\n",
    "      negative_skipgrams_total += len(negative_sampling_candidates_flat)\n",
    "      context_list = [context_word]\n",
    "      context_list.extend(negative_sampling_candidates_flat)\n",
    "      # pretty sure this doesn't need to be recalculated every loop\n",
    "      label_list = [1] + [0]*num_ns\n",
    "\n",
    "      target_list = tf.train.Int64List(value=[target_word])\n",
    "      context_list = tf.train.Int64List(value=context_list)\n",
    "      label_list = tf.train.Int64List(value=label_list)\n",
    "\n",
    "      target = tf.train.Feature(int64_list=target_list)\n",
    "      context = tf.train.Feature(int64_list=context_list)\n",
    "      label = tf.train.Feature(int64_list=label_list)\n",
    "\n",
    "      sample_dict = {\n",
    "        'target': target,\n",
    "        'context': context,\n",
    "        'label': label\n",
    "      }\n",
    "\n",
    "      sample = tf.train.Features(feature=sample_dict)\n",
    "      example = tf.train.Example(features=sample)\n",
    "\n",
    "      writer.write(example.SerializeToString())\n",
    "  print(\"Total Negative Skipgrams: \"+str(negative_skipgrams_total))\n",
    "  print(\"Total Positive Skipgrams: \"+str(positive_skipgrams_total))\n",
    "  # Close tfrecord writer\n",
    "  writer.close()\n",
    "  return positive_skipgrams_total"
   ],
   "execution_count": 76,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5JW9700G3nox",
    "outputId": "db3ab02d-cbd0-4032-96cd-d0860e2740a2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "0c5d052a9c9946018f552e1126911922",
      "e101cc846d7c4b858b0cd0627322b07a",
      "c2413d5f19624437a6474fe9b10ebcab",
      "fe17d6cb96284a4e97b441dff67f35c9",
      "b2b4efe8dc734fbe9d737e6b5d30ba34",
      "53fd6c178331432c8501b03ad37f2d2c",
      "718195d169fb4281a0f97db65b5d14ac",
      "e5f88726f92d4ef7910e3049e62adc4c"
     ]
    }
   },
   "source": [
    "# Don't need to re-run the sampling method every time\n",
    "SEED = 42\n",
    "num_ns = 5\n",
    "positive_skipgrams_total = generate_training_data(\n",
    "    sequences=sequences, \n",
    "    window_size=2, \n",
    "    num_ns=num_ns, \n",
    "    vocab_size=unique_tracks, \n",
    "    seed=SEED)"
   ],
   "execution_count": 77,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5d052a9c9946018f552e1126911922",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=711838.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Total Negative Skipgrams: 120428040\n",
      "Total Positive Skipgrams: 24085608\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OEMPmfWt9K8-"
   },
   "source": [
    "class Word2Vec(Model):\n",
    "  def __init__(self, vocab_size, embedding_dim):\n",
    "    super(Word2Vec, self).__init__()\n",
    "    self.target_embedding = Embedding(vocab_size, \n",
    "                                      embedding_dim,\n",
    "                                      input_length=1,\n",
    "                                      name=\"w2v_embedding\", )\n",
    "    self.context_embedding = Embedding(vocab_size, \n",
    "                                       embedding_dim, \n",
    "                                       input_length=num_ns+1)\n",
    "    self.dots = Dot(axes=(3,2))\n",
    "    self.flatten = Flatten()\n",
    "\n",
    "  def call(self, pair):\n",
    "    target, context = pair\n",
    "    we = self.target_embedding(target)\n",
    "    ce = self.context_embedding(context)\n",
    "    dots = self.dots([ce, we])\n",
    "    return self.flatten(dots)"
   ],
   "execution_count": 78,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "40IhSEXSVfza",
    "outputId": "41ecd2dd-31e0-4606-b42b-4d15512eff11",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "dataset = tf.data.TFRecordDataset([\"/content/drive/MyDrive/CS/AI/Data/embedding_training_data_2020-11-17.tfrecord\"])\n",
    "\n",
    "feature_description = {\n",
    "    'target': tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "    'context': tf.io.FixedLenFeature([num_ns+1], dtype=tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([num_ns+1], dtype=tf.int64)\n",
    "}\n",
    "\n",
    "for raw_record in dataset.take(3):\n",
    "  print(repr(raw_record))\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  # Parse the input `tf.train.Example` proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "def dataset_tupler(example_proto):\n",
    "  # Create tuples of the data: needed for the model.fit function\n",
    "  context = example_proto['context']\n",
    "  context = tf.expand_dims(context, 1)\n",
    "  target = example_proto['target']\n",
    "  target = tf.squeeze(target)\n",
    "  label = example_proto['label']\n",
    "  return ((target, context), label)\n",
    "\n",
    "parsed_dataset = dataset.map(_parse_function)\n",
    "parsed_dataset = parsed_dataset.map(dataset_tupler)\n",
    "\n",
    "for parsed_record in parsed_dataset.take(3):\n",
    "  print(repr(parsed_record))\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "EPOCHS = 3\n",
    "parsed_dataset = parsed_dataset.shuffle(BUFFER_SIZE).repeat(EPOCHS).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(parsed_dataset)"
   ],
   "execution_count": 79,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nH\\n\\x11\\n\\x06target\\x12\\x07\\x1a\\x05\\n\\x03\\xe0\\xad\\x01\\n\\x13\\n\\x05label\\x12\\n\\x1a\\x08\\n\\x06\\x01\\x00\\x00\\x00\\x00\\x00\\n\\x1e\\n\\x07context\\x12\\x13\\x1a\\x11\\n\\x0f\\x96\\xca\\x02\\xac\\x013\\xd1\\xd6\\x0e\\xd5\\xba\\x12\\xf0\\xe7\\x03'>\n",
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nD\\n\\x13\\n\\x05label\\x12\\n\\x1a\\x08\\n\\x06\\x01\\x00\\x00\\x00\\x00\\x00\\n\\x1a\\n\\x07context\\x12\\x0f\\x1a\\r\\n\\x0b\\xe0\\xad\\x01\\xbe\\x8c\\x0e\"\\x05(\\xfe\\x01\\n\\x11\\n\\x06target\\x12\\x07\\x1a\\x05\\n\\x03\\x96\\xca\\x02'>\n",
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nF\\n\\x13\\n\\x05label\\x12\\n\\x1a\\x08\\n\\x06\\x01\\x00\\x00\\x00\\x00\\x00\\n\\x1c\\n\\x07context\\x12\\x11\\x1a\\x0f\\n\\r\\xf0\\xd7\\x16\\xfb\\xde\\x03\\n\\xa7\\x0b\\x83\\xca\\x01`\\n\\x11\\n\\x06target\\x12\\x07\\x1a\\x05\\n\\x03\\x93\\xa0('>\n",
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nE\\n\\x13\\n\\x05label\\x12\\n\\x1a\\x08\\n\\x06\\x01\\x00\\x00\\x00\\x00\\x00\\n\\x1b\\n\\x07context\\x12\\x10\\x1a\\x0e\\n\\x0c\\x8f\\xeb\\x0c\\x01\\xf4\\x0b\\xb8\\x14\\x04\\x8b\\xe0\\x12\\n\\x11\\n\\x06target\\x12\\x07\\x1a\\x05\\n\\x03\\x93\\xa0('>\n",
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nE\\n\\x13\\n\\x05label\\x12\\n\\x1a\\x08\\n\\x06\\x01\\x00\\x00\\x00\\x00\\x00\\n\\x1b\\n\\x07context\\x12\\x10\\x1a\\x0e\\n\\x0c\\x96\\xca\\x02\\xfd\\x06G\\xbd\\x1c\\x00\\x97\\x81\\x0c\\n\\x11\\n\\x06target\\x12\\x07\\x1a\\x05\\n\\x03\\xce\\xa8\\x06'>\n",
      "<BatchDataset shapes: (((1024,), (1024, 6, 1)), (1024, 6)), types: ((tf.int64, tf.int64), tf.int64)>\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f6h45-DU9UIC"
   },
   "source": [
    "embedding_dim = 128\n",
    "word2vec = Word2Vec(unique_tracks, embedding_dim)\n",
    "word2vec.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ],
   "execution_count": 80,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o0RDqePuqknh",
    "outputId": "95a2a317-e9d7-4ddc-f6a2-c450fe2747d8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "steps = math.floor(positive_skipgrams_total / BATCH_SIZE)\n",
    "word2vec.fit(parsed_dataset, epochs=EPOCHS, batch_size=BATCH_SIZE, steps_per_epoch=steps)"
   ],
   "execution_count": 81,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "23521/23521 [==============================] - 17032s 724ms/step - loss: 0.2650 - accuracy: 0.9185\n",
      "Epoch 2/3\n",
      "23521/23521 [==============================] - 17153s 729ms/step - loss: 0.1479 - accuracy: 0.9503\n",
      "Epoch 3/3\n",
      " 9975/23521 [===========>..................] - ETA: 2:46:50 - loss: 0.1154 - accuracy: 0.9631Buffered data was truncated after reaching the output size limit."
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fHCGzLsBNKk8",
    "outputId": "b472e6ea-3bec-4d5d-d89a-c36d56f9760c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    }
   },
   "source": [
    "embedding_layer = word2vec.get_layer('w2v_embedding')\n",
    "embedding_layer = pd.DataFrame(embedding_layer.get_weights()[0])\n",
    "embedding_layer.index = encoder.inverse_transform(embedding_layer.index)\n",
    "embedding_layer.head()"
   ],
   "execution_count": 82,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_00000648-f2ab-4137-bbc3-bcb3ca19401d</th>\n",
       "      <td>-0.010368</td>\n",
       "      <td>-0.000756</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>0.005374</td>\n",
       "      <td>0.041640</td>\n",
       "      <td>0.029533</td>\n",
       "      <td>0.016841</td>\n",
       "      <td>-0.028333</td>\n",
       "      <td>-0.028130</td>\n",
       "      <td>-0.020724</td>\n",
       "      <td>0.038739</td>\n",
       "      <td>-0.017751</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.033822</td>\n",
       "      <td>-0.034419</td>\n",
       "      <td>0.035998</td>\n",
       "      <td>-0.010443</td>\n",
       "      <td>0.013560</td>\n",
       "      <td>-0.015316</td>\n",
       "      <td>-0.034014</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.009997</td>\n",
       "      <td>-0.000399</td>\n",
       "      <td>0.040203</td>\n",
       "      <td>-0.025627</td>\n",
       "      <td>0.028001</td>\n",
       "      <td>-0.009644</td>\n",
       "      <td>0.032128</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>0.020244</td>\n",
       "      <td>-0.034568</td>\n",
       "      <td>-0.031622</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>-0.021977</td>\n",
       "      <td>0.027528</td>\n",
       "      <td>0.047425</td>\n",
       "      <td>0.031596</td>\n",
       "      <td>0.034115</td>\n",
       "      <td>0.048945</td>\n",
       "      <td>-0.028111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.026863</td>\n",
       "      <td>-0.006123</td>\n",
       "      <td>-0.045327</td>\n",
       "      <td>-0.033090</td>\n",
       "      <td>-0.004791</td>\n",
       "      <td>0.018941</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>0.013019</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.042153</td>\n",
       "      <td>-0.002086</td>\n",
       "      <td>0.021195</td>\n",
       "      <td>0.045011</td>\n",
       "      <td>-0.020846</td>\n",
       "      <td>0.041249</td>\n",
       "      <td>-0.031687</td>\n",
       "      <td>0.028507</td>\n",
       "      <td>0.048877</td>\n",
       "      <td>-0.046730</td>\n",
       "      <td>-0.023793</td>\n",
       "      <td>-0.013257</td>\n",
       "      <td>-0.002896</td>\n",
       "      <td>0.019198</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>-0.045728</td>\n",
       "      <td>-0.010646</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>-0.004274</td>\n",
       "      <td>0.041726</td>\n",
       "      <td>0.047934</td>\n",
       "      <td>-0.024515</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.036644</td>\n",
       "      <td>-0.034210</td>\n",
       "      <td>-0.046519</td>\n",
       "      <td>0.040694</td>\n",
       "      <td>-0.022674</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.004469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_00001e3a-61a6-42c9-a39e-25193b18c519</th>\n",
       "      <td>0.021432</td>\n",
       "      <td>-0.042622</td>\n",
       "      <td>0.021523</td>\n",
       "      <td>0.012924</td>\n",
       "      <td>0.006709</td>\n",
       "      <td>-0.040652</td>\n",
       "      <td>0.009869</td>\n",
       "      <td>0.043943</td>\n",
       "      <td>0.042756</td>\n",
       "      <td>-0.013831</td>\n",
       "      <td>0.047426</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.046712</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.010717</td>\n",
       "      <td>0.045156</td>\n",
       "      <td>0.028408</td>\n",
       "      <td>-0.015158</td>\n",
       "      <td>0.049027</td>\n",
       "      <td>0.029514</td>\n",
       "      <td>-0.041287</td>\n",
       "      <td>-0.046607</td>\n",
       "      <td>0.011304</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>-0.002023</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.019580</td>\n",
       "      <td>-0.031961</td>\n",
       "      <td>0.020775</td>\n",
       "      <td>-0.019928</td>\n",
       "      <td>0.044450</td>\n",
       "      <td>-0.018780</td>\n",
       "      <td>-0.035133</td>\n",
       "      <td>0.039770</td>\n",
       "      <td>0.038897</td>\n",
       "      <td>0.044703</td>\n",
       "      <td>-0.003505</td>\n",
       "      <td>0.049766</td>\n",
       "      <td>0.010188</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028019</td>\n",
       "      <td>-0.047318</td>\n",
       "      <td>-0.027254</td>\n",
       "      <td>-0.048201</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.025767</td>\n",
       "      <td>-0.045161</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>-0.002129</td>\n",
       "      <td>-0.034005</td>\n",
       "      <td>-0.010471</td>\n",
       "      <td>-0.016013</td>\n",
       "      <td>-0.006711</td>\n",
       "      <td>-0.029398</td>\n",
       "      <td>-0.033293</td>\n",
       "      <td>-0.001569</td>\n",
       "      <td>-0.030770</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.015632</td>\n",
       "      <td>-0.037159</td>\n",
       "      <td>0.049194</td>\n",
       "      <td>-0.007936</td>\n",
       "      <td>-0.019339</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>-0.005318</td>\n",
       "      <td>0.038007</td>\n",
       "      <td>0.022589</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>-0.037229</td>\n",
       "      <td>0.049011</td>\n",
       "      <td>0.018147</td>\n",
       "      <td>0.048988</td>\n",
       "      <td>-0.013694</td>\n",
       "      <td>-0.041093</td>\n",
       "      <td>-0.021706</td>\n",
       "      <td>0.039041</td>\n",
       "      <td>0.008729</td>\n",
       "      <td>0.007067</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>-0.018898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_000023df-b650-404d-93e5-63655fa87b45</th>\n",
       "      <td>0.008289</td>\n",
       "      <td>-0.043461</td>\n",
       "      <td>-0.035683</td>\n",
       "      <td>-0.028667</td>\n",
       "      <td>-0.026263</td>\n",
       "      <td>-0.002547</td>\n",
       "      <td>-0.013763</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>-0.040731</td>\n",
       "      <td>0.024146</td>\n",
       "      <td>-0.017317</td>\n",
       "      <td>-0.004552</td>\n",
       "      <td>-0.049313</td>\n",
       "      <td>-0.036193</td>\n",
       "      <td>0.022299</td>\n",
       "      <td>-0.027076</td>\n",
       "      <td>-0.027959</td>\n",
       "      <td>0.020817</td>\n",
       "      <td>-0.020325</td>\n",
       "      <td>0.048920</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>-0.027412</td>\n",
       "      <td>-0.016147</td>\n",
       "      <td>-0.015809</td>\n",
       "      <td>-0.025911</td>\n",
       "      <td>-0.012842</td>\n",
       "      <td>-0.026318</td>\n",
       "      <td>-0.014711</td>\n",
       "      <td>-0.006370</td>\n",
       "      <td>0.035134</td>\n",
       "      <td>-0.003191</td>\n",
       "      <td>-0.043959</td>\n",
       "      <td>0.022685</td>\n",
       "      <td>0.005841</td>\n",
       "      <td>0.006767</td>\n",
       "      <td>0.031050</td>\n",
       "      <td>-0.047031</td>\n",
       "      <td>0.044717</td>\n",
       "      <td>-0.000489</td>\n",
       "      <td>0.008295</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049631</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>0.033953</td>\n",
       "      <td>-0.028125</td>\n",
       "      <td>0.042217</td>\n",
       "      <td>-0.020787</td>\n",
       "      <td>0.033487</td>\n",
       "      <td>-0.025581</td>\n",
       "      <td>-0.039036</td>\n",
       "      <td>0.023605</td>\n",
       "      <td>-0.046946</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>-0.045180</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.011074</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>-0.021763</td>\n",
       "      <td>0.025804</td>\n",
       "      <td>-0.029557</td>\n",
       "      <td>-0.022402</td>\n",
       "      <td>0.039740</td>\n",
       "      <td>-0.009913</td>\n",
       "      <td>0.038227</td>\n",
       "      <td>0.035094</td>\n",
       "      <td>0.022852</td>\n",
       "      <td>-0.017575</td>\n",
       "      <td>0.037866</td>\n",
       "      <td>-0.008418</td>\n",
       "      <td>-0.048388</td>\n",
       "      <td>-0.021493</td>\n",
       "      <td>-0.030611</td>\n",
       "      <td>-0.011961</td>\n",
       "      <td>0.031221</td>\n",
       "      <td>0.026194</td>\n",
       "      <td>-0.024017</td>\n",
       "      <td>0.029715</td>\n",
       "      <td>-0.024490</td>\n",
       "      <td>-0.029865</td>\n",
       "      <td>0.040308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_000039da-e48a-444a-b5b9-9ef55f3bb4cb</th>\n",
       "      <td>-0.029590</td>\n",
       "      <td>0.025135</td>\n",
       "      <td>-0.038919</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.048404</td>\n",
       "      <td>0.021141</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>0.035847</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>-0.026996</td>\n",
       "      <td>0.014140</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>-0.010561</td>\n",
       "      <td>-0.040233</td>\n",
       "      <td>-0.023040</td>\n",
       "      <td>0.018876</td>\n",
       "      <td>-0.021468</td>\n",
       "      <td>0.034169</td>\n",
       "      <td>0.024269</td>\n",
       "      <td>0.041373</td>\n",
       "      <td>0.033694</td>\n",
       "      <td>-0.039437</td>\n",
       "      <td>-0.022993</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>-0.017386</td>\n",
       "      <td>-0.011286</td>\n",
       "      <td>-0.008528</td>\n",
       "      <td>-0.044399</td>\n",
       "      <td>-0.023928</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>-0.049717</td>\n",
       "      <td>0.020815</td>\n",
       "      <td>0.006766</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.012036</td>\n",
       "      <td>-0.045808</td>\n",
       "      <td>-0.013981</td>\n",
       "      <td>-0.022119</td>\n",
       "      <td>0.029433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007263</td>\n",
       "      <td>0.030657</td>\n",
       "      <td>0.025952</td>\n",
       "      <td>-0.013677</td>\n",
       "      <td>-0.006830</td>\n",
       "      <td>0.029905</td>\n",
       "      <td>-0.047809</td>\n",
       "      <td>-0.017445</td>\n",
       "      <td>-0.048792</td>\n",
       "      <td>0.004789</td>\n",
       "      <td>-0.015678</td>\n",
       "      <td>0.014983</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>-0.003291</td>\n",
       "      <td>0.049508</td>\n",
       "      <td>-0.013233</td>\n",
       "      <td>0.015233</td>\n",
       "      <td>0.044465</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.009087</td>\n",
       "      <td>-0.004427</td>\n",
       "      <td>0.030559</td>\n",
       "      <td>0.018577</td>\n",
       "      <td>0.028703</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>-0.009263</td>\n",
       "      <td>0.022794</td>\n",
       "      <td>-0.037490</td>\n",
       "      <td>0.024537</td>\n",
       "      <td>-0.022219</td>\n",
       "      <td>-0.015760</td>\n",
       "      <td>0.045489</td>\n",
       "      <td>0.048084</td>\n",
       "      <td>-0.021976</td>\n",
       "      <td>-0.033870</td>\n",
       "      <td>0.014320</td>\n",
       "      <td>-0.039233</td>\n",
       "      <td>-0.001775</td>\n",
       "      <td>-0.004781</td>\n",
       "      <td>0.047986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_00003a96-a43e-4dda-88d8-d69197b29f02</th>\n",
       "      <td>0.015898</td>\n",
       "      <td>-0.019181</td>\n",
       "      <td>-0.030880</td>\n",
       "      <td>-0.022567</td>\n",
       "      <td>-0.044236</td>\n",
       "      <td>0.036118</td>\n",
       "      <td>-0.040491</td>\n",
       "      <td>-0.008395</td>\n",
       "      <td>-0.048526</td>\n",
       "      <td>-0.023702</td>\n",
       "      <td>0.014873</td>\n",
       "      <td>-0.032333</td>\n",
       "      <td>-0.040750</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.028696</td>\n",
       "      <td>-0.026748</td>\n",
       "      <td>-0.033809</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>0.032578</td>\n",
       "      <td>0.047828</td>\n",
       "      <td>0.037266</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>-0.046405</td>\n",
       "      <td>-0.032178</td>\n",
       "      <td>0.049828</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.007130</td>\n",
       "      <td>-0.041010</td>\n",
       "      <td>-0.031535</td>\n",
       "      <td>-0.034920</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>-0.039646</td>\n",
       "      <td>-0.046627</td>\n",
       "      <td>-0.010622</td>\n",
       "      <td>0.043490</td>\n",
       "      <td>0.014362</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>-0.039168</td>\n",
       "      <td>0.012908</td>\n",
       "      <td>-0.029748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049612</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>-0.039903</td>\n",
       "      <td>-0.014623</td>\n",
       "      <td>-0.001555</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>-0.029580</td>\n",
       "      <td>-0.029275</td>\n",
       "      <td>-0.043124</td>\n",
       "      <td>0.049085</td>\n",
       "      <td>-0.008413</td>\n",
       "      <td>-0.025267</td>\n",
       "      <td>-0.045320</td>\n",
       "      <td>-0.010959</td>\n",
       "      <td>0.008710</td>\n",
       "      <td>0.014878</td>\n",
       "      <td>0.045027</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.005140</td>\n",
       "      <td>0.024337</td>\n",
       "      <td>-0.014724</td>\n",
       "      <td>0.017455</td>\n",
       "      <td>0.040929</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>0.014495</td>\n",
       "      <td>-0.012205</td>\n",
       "      <td>-0.029912</td>\n",
       "      <td>0.014997</td>\n",
       "      <td>0.008553</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>-0.039736</td>\n",
       "      <td>-0.033604</td>\n",
       "      <td>0.014658</td>\n",
       "      <td>0.037931</td>\n",
       "      <td>-0.034407</td>\n",
       "      <td>-0.044877</td>\n",
       "      <td>0.009087</td>\n",
       "      <td>-0.027117</td>\n",
       "      <td>0.032983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0         1    ...       126       127\n",
       "t_00000648-f2ab-4137-bbc3-bcb3ca19401d -0.010368 -0.000756  ...  0.001397  0.004469\n",
       "t_00001e3a-61a6-42c9-a39e-25193b18c519  0.021432 -0.042622  ...  0.017242 -0.018898\n",
       "t_000023df-b650-404d-93e5-63655fa87b45  0.008289 -0.043461  ... -0.029865  0.040308\n",
       "t_000039da-e48a-444a-b5b9-9ef55f3bb4cb -0.029590  0.025135  ... -0.004781  0.047986\n",
       "t_00003a96-a43e-4dda-88d8-d69197b29f02  0.015898 -0.019181  ... -0.027117  0.032983\n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 82
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PU4koarVN_bD"
   },
   "source": [
    "current_date_and_time = datetime.datetime.now().date()\n",
    "current_date_and_time_string = str(current_date_and_time)\n",
    "embedding_layer.to_csv('/content/drive/My Drive/CS/AI/Data/embeddings/w2v_embedding_layer_'+current_date_and_time_string)"
   ],
   "execution_count": 83,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPyBP0wTRL1K"
   },
   "source": [
    "## Some Statistics About the Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_8P1Vp7PRLN0"
   },
   "source": [
    "# Cosine distance between some embeddings\n",
    "embedding = pd.read_csv(\"/content/drive/My Drive/CS/AI/Data/w2v_embedding_layer_large\")\n",
    "embedding.rename(columns={'Unnamed: 0': 'track_id_clean'}, inplace=True)\n",
    "embedding.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "h8us_r6HTXFa"
   },
   "source": [
    "unique_tracks = embedding['track_id_clean'].nunique()\n",
    "print(unique_tracks)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4fRBlCfLSr0m"
   },
   "source": [
    "embedding.info()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SwYfv6XIT3r6"
   },
   "source": [
    "def find_max_cosine_similarity(df):\n",
    "  '''\n",
    "    Only calculates cosine similarity between current and next song. Just an indication, no the real max.\n",
    "  '''\n",
    "  max_cosine = -1\n",
    "  max_track_1 = \"\"\n",
    "  max_track_2 = \"\"\n",
    "  for index, row in df.iterrows():\n",
    "    track_1 = row['track_id_clean']\n",
    "    arr_1 = row.values[1:]\n",
    "    if index+1 < len(df):\n",
    "      track_2 = df.iloc[index+1].track_id_clean\n",
    "      arr_2 = df.iloc[index+1].values[1:]\n",
    "      sim = cosine_similarity([arr_1], [arr_2])\n",
    "      if sim > max_cosine:\n",
    "        max_track_1 = track_1\n",
    "        max_track_2 = track_2\n",
    "        max_cosine = sim\n",
    "  return max_track_1, max_track_2, max_cosine"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RVG6kCHvUiux"
   },
   "source": [
    "max_track_1, max_track_2, max_cosine = find_max_cosine_similarity(embedding)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XPrtFrRob3tV"
   },
   "source": [
    "# get tracks and vectors see if values are indeed similar\n",
    "print(\"Most similar tracks: \" + str(max_track_1) + \" and \" + str(max_track_2))\n",
    "print(\"Cosine Similarity: \"+str(max_cosine))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N4wJEXUWb8QO"
   },
   "source": [
    "embedding[embedding['track_id_clean'] == max_track_1].head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dPESZYqlhn5z"
   },
   "source": [
    "embedding[embedding['track_id_clean'] == max_track_2].head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IlZ2CM9bh34y"
   },
   "source": [
    "features = pd.read_csv('/content/drive/My Drive/CS/AI/Data/tf_mini.csv')\n",
    "features[features['track_id'] == 't_9e647859-7e89-4026-b537-956caf38ceeb']"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QwrwJXaClZsR"
   },
   "source": [
    "def find_min_cosine_similarity(df):\n",
    "  '''\n",
    "    Only calculates cosine similarity between current and next song. Just an indication, no the real max.\n",
    "  '''\n",
    "  min_cosine = 1\n",
    "  min_track_1 = \"\"\n",
    "  min_track_2 = \"\"\n",
    "  for index, row in df.iterrows():\n",
    "    track_1 = row['track_id_clean']\n",
    "    arr_1 = row.values[1:]\n",
    "    if index+1 < len(df):\n",
    "      track_2 = df.iloc[index+1].track_id_clean\n",
    "      arr_2 = df.iloc[index+1].values[1:]\n",
    "      sim = cosine_similarity([arr_1], [arr_2])\n",
    "      if sim < min_cosine:\n",
    "        min_track_1 = track_1\n",
    "        min_track_2 = track_2\n",
    "        min_cosine = sim\n",
    "  return min_track_1, min_track_2, min_cosine"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PcShPfZOluai"
   },
   "source": [
    "min_track_1, min_track_2, min_cosine = find_min_cosine_similarity(embedding)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VbXBuT0qospK"
   },
   "source": [
    "# get tracks and vectors see if values are indeed similar\n",
    "print(\"Most similar tracks: \" + str(min_track_1) + \" and \" + str(min_track_2))\n",
    "print(\"Cosine Similarity: \"+str(min_cosine))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j4-KY5f-qwBX"
   },
   "source": [
    "# Set up a logs directory, so Tensorboard knows where to look for files\n",
    "LOG_DIR = '/logs/'\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)\n",
    "\n",
    "with open(os.path.join(LOG_DIR, 'metadata.tsv'), \"w\") as f:\n",
    "  for index, id in embedding['track_id_clean'].iterrows():\n",
    "    f.write(\"{}\\n\".format(id))\n",
    "\n",
    "\n",
    "weights = embedding.drop(columns=['track_id_clean']).values\n",
    "weights = tf.Variable(weights, name='Track Embedding')\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(LOG_DIR, \"embedding.ckpt\"))\n",
    "\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(LOG_DIR, config)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "24abvZKYtlPg"
   },
   "source": [
    "%tensorboard --logdir=logs"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}